{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an supervised classification example taken from the KDD 2009 cup.  A copy of the data and details can be found here: [https://github.com/WinVector/PDSwR2/tree/master/KDD2009](https://github.com/WinVector/PDSwR2/tree/master/KDD2009).  The problem was to predict account cancellation (\"churn\") from very messy data (column names not given, numeric and categorical variables, many missing values, some categorical variables with a large number of possible levels).  In this example we show how to quickly use `vtreat` to prepare the data for modeling.  `vtreat` takes in `Pandas` `DataFrame`s and returns both a treatment plan and a clean `Pandas` `DataFrame` ready for modeling."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# To install:\n",
    "!pip install https://github.com/WinVector/pyvtreat/raw/master/pkg/dist/vtreat-0.1.tar.gz\n",
    "!pip install https://github.com/WinVector/wvpy/raw/master/pkg/dist/wvpy-0.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our packages/modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xgboost\n",
    "import vtreat\n",
    "import numpy\n",
    "import numpy.random\n",
    "import wvpy.util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in explanitory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 230)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# data from https://github.com/WinVector/PDSwR2/tree/master/KDD2009\n",
    "dir = \"../../../PracticalDataScienceWithR2nd/PDSwR2/KDD2009/\"\n",
    "d = pandas.read_csv(dir + 'orange_small_train.data.gz', sep='\\t', header=0)\n",
    "vars = [c for c in d.columns]\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dependent variable we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn = pandas.read_csv(dir + 'orange_small_train_churn.labels.txt', header=None)\n",
    "churn.columns = [\"churn\"]\n",
    "churn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    46328\n",
       " 1     3672\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrange test/train split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = d.shape[0]\n",
    "is_train = numpy.random.uniform(size=n)<=0.9\n",
    "is_test = numpy.logical_not(is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = d.loc[is_train, :].copy()\n",
    "churn_train = numpy.asarray(churn.loc[is_train, :][\"churn\"]==1)\n",
    "d_test = d.loc[is_test, :].copy()\n",
    "churn_test = numpy.asarray(churn.loc[is_test, :][\"churn\"]==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the dependent variables.  They are a mess, many missing values.  Categorical variables that can not be directly used without some re-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var8</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>...</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "      <th>Var230</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>2Kb5FSF</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fKCe</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Al6ZaUT</td>\n",
       "      <td>NKv4yOc</td>\n",
       "      <td>jySVZNlOJy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>Qu4f</td>\n",
       "      <td>02N6s8f</td>\n",
       "      <td>ib5G6X1eUxUn6</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>CE7uk3u</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>1J2cvxe</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>F2FyR07IdsN7I</td>\n",
       "      <td>mj86</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oslk</td>\n",
       "      <td>XlgxB9z</td>\n",
       "      <td>LM8l689qOp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kG3k</td>\n",
       "      <td>FSa2</td>\n",
       "      <td>RAYp</td>\n",
       "      <td>55YFVY9</td>\n",
       "      <td>am7c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1  Var2  Var3  Var4  Var5    Var6  Var7  Var8  Var9  Var10  ...  \\\n",
       "1   NaN   NaN   NaN   NaN   NaN   525.0   0.0   NaN   NaN    NaN  ...   \n",
       "2   NaN   NaN   NaN   NaN   NaN  5236.0   7.0   NaN   NaN    NaN  ...   \n",
       "3   NaN   NaN   NaN   NaN   NaN     NaN   0.0   NaN   NaN    NaN  ...   \n",
       "4   NaN   NaN   NaN   NaN   NaN  1029.0   7.0   NaN   NaN    NaN  ...   \n",
       "6   NaN   NaN   NaN   NaN   NaN  1680.0   7.0   NaN   NaN    NaN  ...   \n",
       "\n",
       "    Var221   Var222      Var223  Var224  Var225  Var226   Var227  \\\n",
       "1     oslk  2Kb5FSF  LM8l689qOp     NaN     NaN    fKCe     RAYp   \n",
       "2  Al6ZaUT  NKv4yOc  jySVZNlOJy     NaN    kG3k    Qu4f  02N6s8f   \n",
       "3     oslk  CE7uk3u  LM8l689qOp     NaN     NaN    FSa2     RAYp   \n",
       "4     oslk  1J2cvxe  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "6     oslk  XlgxB9z  LM8l689qOp     NaN    kG3k    FSa2     RAYp   \n",
       "\n",
       "          Var228  Var229  Var230  \n",
       "1  F2FyR07IdsN7I     NaN     NaN  \n",
       "2  ib5G6X1eUxUn6    am7c     NaN  \n",
       "3  F2FyR07IdsN7I     NaN     NaN  \n",
       "4  F2FyR07IdsN7I    mj86     NaN  \n",
       "6        55YFVY9    am7c     NaN  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44993, 230)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try building a model directly off this data (this will fail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame.dtypes for data must be int, float or bool.\n",
      "                Did not expect the data types in fields Var191, Var192, Var193, Var194, Var195, Var196, Var197, Var198, Var199, Var200, Var201, Var202, Var203, Var204, Var205, Var206, Var207, Var208, Var210, Var211, Var212, Var213, Var214, Var215, Var216, Var217, Var218, Var219, Var220, Var221, Var222, Var223, Var224, Var225, Var226, Var227, Var228, Var229\n"
     ]
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=10, max_depth=3, objective='binary:logistic')\n",
    "try:\n",
    "    fitter.fit(d_train, churn_train)\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly prepare a data frame with none of these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our treatment plan, this has the `sklearn.pipeline.Pipeline` interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = vtreat.BinomialOutcomeTreatment(outcome_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.fit_transform()` to get a special copy of the treated training data that has cross-validated mitigations againsst nested model bias. We call this a \"cross frame.\" `.fit_transform()` is deliberately a different `DataFrame` than what would be returned by `.fit().transform()` (the `.fit().transform()` would damage the modeling effort due nested model bias, the `.fit_transform()` \"cross frame\" uses cross-validation techniques similar to \"stacking\" to mitigate these issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_frame = plan.fit_transform(d_train, churn_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the new data.  This frame is guaranteed to be all numeric with no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1_is_bad</th>\n",
       "      <th>Var2_is_bad</th>\n",
       "      <th>Var3_is_bad</th>\n",
       "      <th>Var4_is_bad</th>\n",
       "      <th>Var5_is_bad</th>\n",
       "      <th>Var6_is_bad</th>\n",
       "      <th>Var7_is_bad</th>\n",
       "      <th>Var9_is_bad</th>\n",
       "      <th>Var10_is_bad</th>\n",
       "      <th>Var11_is_bad</th>\n",
       "      <th>...</th>\n",
       "      <th>Var228_logit_code</th>\n",
       "      <th>Var228_prevalence_code</th>\n",
       "      <th>Var228_lev_F2FyR07IdsN7I</th>\n",
       "      <th>Var228_lev_55YFVY9</th>\n",
       "      <th>Var228_lev_ib5G6X1eUxUn6</th>\n",
       "      <th>Var229_logit_code</th>\n",
       "      <th>Var229_prevalence_code</th>\n",
       "      <th>Var229_lev__NA_</th>\n",
       "      <th>Var229_lev_am7c</th>\n",
       "      <th>Var229_lev_mj86</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079399</td>\n",
       "      <td>0.654724</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>0.567933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019022</td>\n",
       "      <td>0.052986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012550</td>\n",
       "      <td>0.654724</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.047578</td>\n",
       "      <td>0.567933</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019022</td>\n",
       "      <td>0.654724</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002943</td>\n",
       "      <td>0.196142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007156</td>\n",
       "      <td>0.086591</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052476</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 519 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Var1_is_bad  Var2_is_bad  Var3_is_bad  Var4_is_bad  Var5_is_bad  \\\n",
       "0          1.0          1.0          1.0          1.0          1.0   \n",
       "1          1.0          1.0          1.0          1.0          1.0   \n",
       "2          1.0          1.0          1.0          1.0          1.0   \n",
       "3          1.0          1.0          1.0          1.0          1.0   \n",
       "4          1.0          1.0          1.0          1.0          1.0   \n",
       "\n",
       "   Var6_is_bad  Var7_is_bad  Var9_is_bad  Var10_is_bad  Var11_is_bad  ...  \\\n",
       "0          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "1          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "2          1.0          0.0          1.0           1.0           1.0  ...   \n",
       "3          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "4          0.0          0.0          1.0           1.0           1.0  ...   \n",
       "\n",
       "   Var228_logit_code  Var228_prevalence_code  Var228_lev_F2FyR07IdsN7I  \\\n",
       "0           0.079399                0.654724                         1   \n",
       "1          -0.019022                0.052986                         0   \n",
       "2          -0.012550                0.654724                         1   \n",
       "3          -0.019022                0.654724                         1   \n",
       "4          -0.007156                0.086591                         0   \n",
       "\n",
       "   Var228_lev_55YFVY9  Var228_lev_ib5G6X1eUxUn6  Var229_logit_code  \\\n",
       "0                   0                         0          -0.002943   \n",
       "1                   0                         1          -0.002943   \n",
       "2                   0                         0          -0.047578   \n",
       "3                   0                         0          -0.002943   \n",
       "4                   1                         0           0.052476   \n",
       "\n",
       "   Var229_prevalence_code  Var229_lev__NA_  Var229_lev_am7c  Var229_lev_mj86  \n",
       "0                0.567933                1                0                0  \n",
       "1                0.234303                0                1                0  \n",
       "2                0.567933                1                0                0  \n",
       "3                0.196142                0                0                1  \n",
       "4                0.234303                0                1                0  \n",
       "\n",
       "[5 rows x 519 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44993, 519)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a recommended subset of the new derived variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>treatment</th>\n",
       "      <th>y_aware</th>\n",
       "      <th>PearsonR</th>\n",
       "      <th>significance</th>\n",
       "      <th>vcount</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Var1_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>2.523180e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Var2_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>5.838237e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Var3_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>5.990940e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Var4_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>5.899282e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Var5_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Var6_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.031957</td>\n",
       "      <td>1.201349e-11</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Var7_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.027287</td>\n",
       "      <td>7.085969e-09</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Var9_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>2.523180e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Var10_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Var11_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>5.990940e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Var12_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>3.024083e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Var13_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.027287</td>\n",
       "      <td>7.085969e-09</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Var14_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>5.990940e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Var16_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Var17_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>5.899282e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Var18_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>5.899282e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Var19_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018936</td>\n",
       "      <td>5.899282e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Var21_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.031957</td>\n",
       "      <td>1.201349e-11</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Var22_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032282</td>\n",
       "      <td>7.430900e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Var23_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Var24_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.008393</td>\n",
       "      <td>7.502604e-02</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Var25_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032282</td>\n",
       "      <td>7.430900e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Var26_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Var27_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>5.651050e-05</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Var28_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032300</td>\n",
       "      <td>7.239047e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Var29_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>2.523180e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Var30_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>2.523180e-01</td>\n",
       "      <td>193.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Var33_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.015327</td>\n",
       "      <td>1.149089e-03</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Var34_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>5.838237e-04</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Var35_is_bad</td>\n",
       "      <td>missing_indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.032282</td>\n",
       "      <td>7.430900e-12</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Var224_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>1.511689e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Var225_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.010205</td>\n",
       "      <td>3.041446e-02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Var225_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055702</td>\n",
       "      <td>2.927685e-32</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Var225_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056823</td>\n",
       "      <td>1.668357e-33</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Var225_lev_ELof</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.041974</td>\n",
       "      <td>5.237778e-19</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Var225_lev_kG3k</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.018779</td>\n",
       "      <td>6.789533e-05</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Var226_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>9.962195e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Var226_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020989</td>\n",
       "      <td>8.492498e-06</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Var226_lev_FSa2</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.031002</td>\n",
       "      <td>4.787303e-11</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Var226_lev_Qu4f</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.010461</td>\n",
       "      <td>2.649302e-02</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Var226_lev_WqMG</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>9.686270e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Var226_lev_szEZ</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.016973</td>\n",
       "      <td>3.176913e-04</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Var226_lev_7P5s</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.020671</td>\n",
       "      <td>1.159446e-05</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>Var226_lev_fKCe</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>8.426815e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Var226_lev_Aoh3</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.003309</td>\n",
       "      <td>4.827271e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>Var227_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004690</td>\n",
       "      <td>3.198297e-01</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Var227_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.049771</td>\n",
       "      <td>4.400715e-26</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Var227_lev_RAYp</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.051097</td>\n",
       "      <td>2.099834e-27</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Var227_lev_ZI9m</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.045747</td>\n",
       "      <td>2.775862e-22</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Var227_lev_6fzt</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>1.391602e-01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Var228_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>6.357821e-02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Var228_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065234</td>\n",
       "      <td>1.246020e-43</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Var228_lev_F2FyR07IdsN7I</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065709</td>\n",
       "      <td>3.031793e-44</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>Var228_lev_55YFVY9</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.027765</td>\n",
       "      <td>3.852507e-09</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Var228_lev_ib5G6X1eUxUn6</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033030</td>\n",
       "      <td>2.419201e-12</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Var229_logit_code</td>\n",
       "      <td>logit_code</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>8.466806e-02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Var229_prevalence_code</td>\n",
       "      <td>prevalance</td>\n",
       "      <td>False</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>4.694228e-39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Var229_lev__NA_</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>1.946361e-39</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Var229_lev_am7c</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.039983</td>\n",
       "      <td>2.172149e-17</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Var229_lev_mj86</td>\n",
       "      <td>indicator</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.034312</td>\n",
       "      <td>3.336601e-13</td>\n",
       "      <td>77.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     variable          treatment  y_aware  PearsonR  \\\n",
       "0                 Var1_is_bad  missing_indicator    False  0.005397   \n",
       "1                 Var2_is_bad  missing_indicator    False  0.016212   \n",
       "2                 Var3_is_bad  missing_indicator    False  0.016179   \n",
       "3                 Var4_is_bad  missing_indicator    False  0.018936   \n",
       "4                 Var5_is_bad  missing_indicator    False  0.018983   \n",
       "5                 Var6_is_bad  missing_indicator    False -0.031957   \n",
       "6                 Var7_is_bad  missing_indicator    False -0.027287   \n",
       "7                 Var9_is_bad  missing_indicator    False  0.005397   \n",
       "8                Var10_is_bad  missing_indicator    False  0.018983   \n",
       "9                Var11_is_bad  missing_indicator    False  0.016179   \n",
       "10               Var12_is_bad  missing_indicator    False  0.004862   \n",
       "11               Var13_is_bad  missing_indicator    False -0.027287   \n",
       "12               Var14_is_bad  missing_indicator    False  0.016179   \n",
       "13               Var16_is_bad  missing_indicator    False  0.018983   \n",
       "14               Var17_is_bad  missing_indicator    False  0.018936   \n",
       "15               Var18_is_bad  missing_indicator    False  0.018936   \n",
       "16               Var19_is_bad  missing_indicator    False  0.018936   \n",
       "17               Var21_is_bad  missing_indicator    False -0.031957   \n",
       "18               Var22_is_bad  missing_indicator    False -0.032282   \n",
       "19               Var23_is_bad  missing_indicator    False  0.018983   \n",
       "20               Var24_is_bad  missing_indicator    False -0.008393   \n",
       "21               Var25_is_bad  missing_indicator    False -0.032282   \n",
       "22               Var26_is_bad  missing_indicator    False  0.018983   \n",
       "23               Var27_is_bad  missing_indicator    False  0.018983   \n",
       "24               Var28_is_bad  missing_indicator    False -0.032300   \n",
       "25               Var29_is_bad  missing_indicator    False  0.005397   \n",
       "26               Var30_is_bad  missing_indicator    False  0.005397   \n",
       "27               Var33_is_bad  missing_indicator    False  0.015327   \n",
       "28               Var34_is_bad  missing_indicator    False  0.016212   \n",
       "29               Var35_is_bad  missing_indicator    False -0.032282   \n",
       "..                        ...                ...      ...       ...   \n",
       "489           Var224_lev__NA_          indicator    False  0.006767   \n",
       "490         Var225_logit_code         logit_code     True -0.010205   \n",
       "491    Var225_prevalence_code         prevalance    False  0.055702   \n",
       "492           Var225_lev__NA_          indicator    False  0.056823   \n",
       "493           Var225_lev_ELof          indicator    False -0.041974   \n",
       "494           Var225_lev_kG3k          indicator    False -0.018779   \n",
       "495         Var226_logit_code         logit_code     True  0.000022   \n",
       "496    Var226_prevalence_code         prevalance    False  0.020989   \n",
       "497           Var226_lev_FSa2          indicator    False  0.031002   \n",
       "498           Var226_lev_Qu4f          indicator    False -0.010461   \n",
       "499           Var226_lev_WqMG          indicator    False  0.000185   \n",
       "500           Var226_lev_szEZ          indicator    False -0.016973   \n",
       "501           Var226_lev_7P5s          indicator    False -0.020671   \n",
       "502           Var226_lev_fKCe          indicator    False -0.000936   \n",
       "503           Var226_lev_Aoh3          indicator    False -0.003309   \n",
       "504         Var227_logit_code         logit_code     True  0.004690   \n",
       "505    Var227_prevalence_code         prevalance    False  0.049771   \n",
       "506           Var227_lev_RAYp          indicator    False  0.051097   \n",
       "507           Var227_lev_ZI9m          indicator    False -0.045747   \n",
       "508           Var227_lev_6fzt          indicator    False -0.006972   \n",
       "509         Var228_logit_code         logit_code     True  0.008746   \n",
       "510    Var228_prevalence_code         prevalance    False  0.065234   \n",
       "511  Var228_lev_F2FyR07IdsN7I          indicator    False  0.065709   \n",
       "512        Var228_lev_55YFVY9          indicator    False -0.027765   \n",
       "513  Var228_lev_ib5G6X1eUxUn6          indicator    False -0.033030   \n",
       "514         Var229_logit_code         logit_code     True  0.008129   \n",
       "515    Var229_prevalence_code         prevalance    False  0.061575   \n",
       "516           Var229_lev__NA_          indicator    False  0.061889   \n",
       "517           Var229_lev_am7c          indicator    False -0.039983   \n",
       "518           Var229_lev_mj86          indicator    False -0.034312   \n",
       "\n",
       "     significance  vcount  recommended  \n",
       "0    2.523180e-01   193.0        False  \n",
       "1    5.838237e-04   193.0         True  \n",
       "2    5.990940e-04   193.0         True  \n",
       "3    5.899282e-05   193.0         True  \n",
       "4    5.651050e-05   193.0         True  \n",
       "5    1.201349e-11   193.0         True  \n",
       "6    7.085969e-09   193.0         True  \n",
       "7    2.523180e-01   193.0        False  \n",
       "8    5.651050e-05   193.0         True  \n",
       "9    5.990940e-04   193.0         True  \n",
       "10   3.024083e-01   193.0        False  \n",
       "11   7.085969e-09   193.0         True  \n",
       "12   5.990940e-04   193.0         True  \n",
       "13   5.651050e-05   193.0         True  \n",
       "14   5.899282e-05   193.0         True  \n",
       "15   5.899282e-05   193.0         True  \n",
       "16   5.899282e-05   193.0         True  \n",
       "17   1.201349e-11   193.0         True  \n",
       "18   7.430900e-12   193.0         True  \n",
       "19   5.651050e-05   193.0         True  \n",
       "20   7.502604e-02   193.0        False  \n",
       "21   7.430900e-12   193.0         True  \n",
       "22   5.651050e-05   193.0         True  \n",
       "23   5.651050e-05   193.0         True  \n",
       "24   7.239047e-12   193.0         True  \n",
       "25   2.523180e-01   193.0        False  \n",
       "26   2.523180e-01   193.0        False  \n",
       "27   1.149089e-03   193.0         True  \n",
       "28   5.838237e-04   193.0         True  \n",
       "29   7.430900e-12   193.0         True  \n",
       "..            ...     ...          ...  \n",
       "489  1.511689e-01    77.0        False  \n",
       "490  3.041446e-02    38.0        False  \n",
       "491  2.927685e-32    38.0         True  \n",
       "492  1.668357e-33    77.0         True  \n",
       "493  5.237778e-19    77.0         True  \n",
       "494  6.789533e-05    77.0         True  \n",
       "495  9.962195e-01    38.0        False  \n",
       "496  8.492498e-06    38.0         True  \n",
       "497  4.787303e-11    77.0         True  \n",
       "498  2.649302e-02    77.0        False  \n",
       "499  9.686270e-01    77.0        False  \n",
       "500  3.176913e-04    77.0         True  \n",
       "501  1.159446e-05    77.0         True  \n",
       "502  8.426815e-01    77.0        False  \n",
       "503  4.827271e-01    77.0        False  \n",
       "504  3.198297e-01    38.0        False  \n",
       "505  4.400715e-26    38.0         True  \n",
       "506  2.099834e-27    77.0         True  \n",
       "507  2.775862e-22    77.0         True  \n",
       "508  1.391602e-01    77.0        False  \n",
       "509  6.357821e-02    38.0        False  \n",
       "510  1.246020e-43    38.0         True  \n",
       "511  3.031793e-44    77.0         True  \n",
       "512  3.852507e-09    77.0         True  \n",
       "513  2.419201e-12    77.0         True  \n",
       "514  8.466806e-02    38.0        False  \n",
       "515  4.694228e-39    38.0         True  \n",
       "516  1.946361e-39    77.0         True  \n",
       "517  2.172149e-17    77.0         True  \n",
       "518  3.336601e-13    77.0         True  \n",
       "\n",
       "[519 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan.score_frame_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vars = numpy.asarray(plan.score_frame_[\"variable\"][plan.score_frame_[\"recommended\"]])\n",
    "len(model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = xgboost.DMatrix(data=cross_frame.loc[:, model_vars], label=churn_train)\n",
    "x_parameters = {\"max_depth\":3, \"objective\":'binary:logistic'}\n",
    "cv = xgboost.cv(x_parameters, fd, num_boost_round=100, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073156</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.001352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073245</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073267</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.073278</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "0          0.073156         0.000669         0.073500        0.001352\n",
       "1          0.073245         0.000730         0.073278        0.001512\n",
       "2          0.073267         0.000747         0.073278        0.001512\n",
       "3          0.073278         0.000756         0.073278        0.001512\n",
       "4          0.073278         0.000756         0.073278        0.001512"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.070778</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>0.001557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.070722</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.072678</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-error-mean  train-error-std  test-error-mean  test-error-std\n",
       "80          0.070778         0.000411         0.072678        0.001557\n",
       "82          0.070722         0.000333         0.072678        0.001509"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = cv.loc[cv[\"test-error-mean\"]<= min(cv[\"test-error-mean\"] + 1.0e-9), :]\n",
    "best\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree = best.index.values[0]\n",
    "ntree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=3, min_child_weight=1, missing=None, n_estimators=80,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitter = xgboost.XGBClassifier(n_estimators=ntree, max_depth=3, objective='binary:logistic')\n",
    "fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fitter.fit(cross_frame.loc[:, model_vars], churn_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the data transform to our held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_processed = plan.transform(d_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the quality of the model score on the held-out data.  This AUC is not great, but in the ballpark of the original contest winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pf = pandas.DataFrame({\"churn\":churn_test})\n",
    "preds = model.predict_proba(test_processed.loc[:, model_vars])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf[\"pred\"] = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7634173862982153"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wvpy.util.plot_roc(pf[\"pred\"], pf[\"churn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we dealt with many problem columns at once, and in a statistically sound manner. More on the `vtreat` package for Python can be found here: [https://github.com/WinVector/pyvtreat](https://github.com/WinVector/pyvtreat).  Details on the `R` version can be found here: [https://github.com/WinVector/vtreat](https://github.com/WinVector/vtreat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to [R solution](https://github.com/WinVector/PDSwR2/blob/master/KDD2009/KDD2009vtreat.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
